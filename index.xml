<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Puya Latafat</title>
    <link>https://pylat.github.io/</link>
    <description>Recent content on Puya Latafat</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language><atom:link href="https://pylat.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title></title>
      <link>https://pylat.github.io/contact/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pylat.github.io/contact/</guid>
      <description>Mailing information: Puya Latafat
KU Leuven
Dept. Electrical Engineering (ESAT)
Kasteelpark Arenberg 10, bus 2446
3001 Leuven
Belgium
Contact information: email: puya.latafat[at]kuleuven[dot]be</description>
    </item>
    
    <item>
      <title>About me</title>
      <link>https://pylat.github.io/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pylat.github.io/about/</guid>
      <description>I am currently a postdoc at KU Leuven (Belgium). I received my PhD in July 2020 jointly from KU Leuven (Belgium) and IMT Lucca (Italy). My PhD advisors were Prof. Panagiotis Patrinos and Prof. Alberto Bemporad. My PhD thesis can be found here. Currently, my research focuses on nonsmooth and nonconvex optimization, and its applications in machine learning and control.</description>
    </item>
    
    <item>
      <title>Publications</title>
      <link>https://pylat.github.io/publications/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pylat.github.io/publications/</guid>
      <description>Preprints  Latafat P., Themelis A., Villa S., Patrinos P., &amp;ldquo;AdaBiM: An adaptive proximal gradient method for structured convex bilevel optimization&amp;rdquo; arXiv:2305.03559, 2023 Latafat P., Themelis A., Stella L., Patrinos P., &amp;ldquo;Adaptive proximal algorithms for convex optimization under local Lipschitz continuity of the gradient&amp;rdquo; arXiv:2301.04431, 2023 Evens B., Pas P., Latafat P., Patrinos P., &amp;ldquo;Convergence of proximal point algorithm and Douglas&amp;ndash;Rachford Splitting in the Absence of Monotonicity&amp;rdquo; arXiv:2305.03605, 2023 Behmandpoor P.</description>
    </item>
    
    <item>
      <title>Related software</title>
      <link>https://pylat.github.io/software/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pylat.github.io/software/</guid>
      <description>adaptive-proximal-algorithms: Julia implementation of adaptive proxima gradient method (adaPGM) and adaptive primal-dual method (adaPDM) based on the results here.
  CIAOAlgorithms.jl: Julia implementation of several popular stochastic and incremental methods for finite sum minimization problems, including our extention of the Finito/MISO/DIAG algorithm for fully nonconvex problems based on the results presented here.
  Primal-dual algorithms presented in here and here have been implemented as part of the generic Julia solver ProximalAlgorithms.</description>
    </item>
    
  </channel>
</rss>
